{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_deep learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#SOM 신경망\n",
        "손글씨 이미지 데이터 구분"
      ],
      "metadata": {
        "id": "2rylqtw6uChN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVD2saX_t8BS"
      },
      "outputs": [],
      "source": [
        "from math import sqrt\n",
        "\n",
        "from numpy import (array, unravel_index, nditer, linalg, random, subtract,\n",
        "                   power, exp, pi, zeros, arange, outer, meshgrid, dot)\n",
        "from collections import defaultdict\n",
        "from warnings import warn\n",
        "\n",
        "\n",
        "def fast_norm(x):\n",
        "    \"\"\"Returns norm-2 of a 1-D numpy array.\n",
        "\n",
        "    * faster than linalg.norm in case of 1-D arrays (numpy 1.9.2rc1).\n",
        "    \"\"\"\n",
        "    return sqrt(dot(x, x.T))\n",
        "\n",
        "\n",
        "class Som:\n",
        "    def __init__(self,x,y,input_len,sigma=1.0,learning_rate=0.5,random_seed=None):\n",
        "        \"\"\"\n",
        "            Initializes a Self Organizing Maps.\n",
        "            x,y - dimensions of the SOM\n",
        "            input_len - number of the elements of the vectors in input\n",
        "            sigma - spread of the neighborhood function (Gaussian), needs to be adequate to the dimensions of the map.\n",
        "            (at the iteration t we have sigma(t) = sigma / (1 + t/T) where T is #num_iteration/2)\n",
        "            learning_rate - initial learning rate\n",
        "            (at the iteration t we have learning_rate(t) = learning_rate / (1 + t/T) where T is #num_iteration/2)\n",
        "            random_seed, random seed to use.\n",
        "        \"\"\"\n",
        "        if sigma >= x/2.0 or sigma >= y/2.0:\n",
        "            warn('Warning: sigma is too high for the dimension of the map.')\n",
        "        if random_seed:\n",
        "            self.random_generator = random.RandomState(random_seed)\n",
        "        else:\n",
        "            self.random_generator = random.RandomState(random_seed)\n",
        "        self.learning_rate = learning_rate\n",
        "        self.sigma = sigma\n",
        "        self.weights = self.random_generator.rand(x,y,input_len)*2-1 # random initialization\n",
        "        self.weights = array([v/linalg.norm(v) for v in self.weights]) # normalization\n",
        "        self.activation_map = zeros((x,y))\n",
        "        self.neigx = arange(x)\n",
        "        self.neigy = arange(y) # used to evaluate the neighborhood function\n",
        "        self.neighborhood = self.gaussian\n",
        "\n",
        "    def _activate(self,x):\n",
        "        \"\"\" Updates matrix activation_map, in this matrix the element i,j is the response of the neuron i,j to x \"\"\"\n",
        "        s = subtract(x,self.weights) # x - w\n",
        "        it = nditer(self.activation_map, flags=['multi_index'])\n",
        "        while not it.finished:\n",
        "            self.activation_map[it.multi_index] = fast_norm(s[it.multi_index]) # || x - w ||\n",
        "            it.iternext()\n",
        "\n",
        "    def activate(self,x):\n",
        "        \"\"\" Returns the activation map to x \"\"\"\n",
        "        self._activate(x)\n",
        "        return self.activation_map\n",
        "\n",
        "    def gaussian(self,c,sigma):\n",
        "        \"\"\" Returns a Gaussian centered in c \"\"\"\n",
        "        d = 2*pi*sigma*sigma\n",
        "        ax = exp(-power(self.neigx-c[0],2)/d)\n",
        "        ay = exp(-power(self.neigy-c[1],2)/d)\n",
        "        return outer(ax,ay) # the external product gives a matrix\n",
        "\n",
        "    def diff_gaussian(self,c,sigma):\n",
        "        \"\"\" Mexican hat centered in c (unused) \"\"\"\n",
        "        xx,yy = meshgrid(self.neigx,self.neigy)\n",
        "        p = power(xx-c[0],2) + power(yy-c[1],2)\n",
        "        d = 2*pi*sigma*sigma\n",
        "        return exp(-(p)/d)*(1-2/d*p)\n",
        "\n",
        "    def winner(self,x):\n",
        "        \"\"\" Computes the coordinates of the winning neuron for the sample x \"\"\"\n",
        "        self._activate(x)\n",
        "        return unravel_index(self.activation_map.argmin(),self.activation_map.shape)\n",
        "\n",
        "    def update(self,x,win,t):\n",
        "        \"\"\"\n",
        "            Updates the weights of the neurons.\n",
        "            x - current pattern to learn\n",
        "            win - position of the winning neuron for x (array or tuple).\n",
        "            t - iteration index\n",
        "        \"\"\"\n",
        "        # eta(t) = eta(0) / (1 + t/T) \n",
        "        # keeps the learning rate nearly constant for the first T iterations and then adjusts it\n",
        "        eta = self.learning_rate/(1+t/self.T)\n",
        "        sig = self.sigma/(1+t/self.T) # sigma and learning rate decrease with the same rule\n",
        "        g = self.neighborhood(win,sig)*eta # improves the performances\n",
        "        it = nditer(g, flags=['multi_index'])\n",
        "        while not it.finished:\n",
        "            # eta * neighborhood_function * (x-w)\n",
        "            self.weights[it.multi_index] += g[it.multi_index]*(x-self.weights[it.multi_index])            \n",
        "            # normalization\n",
        "            self.weights[it.multi_index] = self.weights[it.multi_index] / fast_norm(self.weights[it.multi_index])\n",
        "            it.iternext()\n",
        "\n",
        "    def quantization(self,data):\n",
        "        \"\"\" Assigns a code book (weights vector of the winning neuron) to each sample in data. \"\"\"\n",
        "        q = zeros(data.shape)\n",
        "        for i,x in enumerate(data):\n",
        "            q[i] = self.weights[self.winner(x)]\n",
        "        return q\n",
        "\n",
        "\n",
        "    def random_weights_init(self,data):\n",
        "        \"\"\" Initializes the weights of the SOM picking random samples from data \"\"\"\n",
        "        it = nditer(self.activation_map, flags=['multi_index'])\n",
        "        while not it.finished:\n",
        "            self.weights[it.multi_index] = data[int(self.random_generator.rand()*len(data)-1)]\n",
        "            self.weights[it.multi_index] = self.weights[it.multi_index]/fast_norm(self.weights[it.multi_index])\n",
        "            it.iternext()\n",
        "\n",
        "    def train_random(self,data,num_iteration):        \n",
        "        \"\"\" Trains the SOM picking samples at random from data \"\"\"\n",
        "        self._init_T(num_iteration)        \n",
        "        for iteration in range(num_iteration):\n",
        "            rand_i = int(round(self.random_generator.rand()*len(data)-1)) # pick a random sample\n",
        "            self.update(data[rand_i],self.winner(data[rand_i]),iteration)\n",
        "\n",
        "    def train_batch(self,data,num_iteration):\n",
        "        \"\"\" Trains using all the vectors in data sequentially \"\"\"\n",
        "        self._init_T(len(data)*num_iteration)\n",
        "        iteration = 0\n",
        "        while iteration < num_iteration:\n",
        "            idx = iteration % (len(data)-1)\n",
        "            self.update(data[idx],self.winner(data[idx]),iteration)\n",
        "            iteration += 1\n",
        "\n",
        "    def _init_T(self,num_iteration):\n",
        "        \"\"\" Initializes the parameter T needed to adjust the learning rate \"\"\"\n",
        "        self.T = num_iteration/2 # keeps the learning rate nearly constant for the first half of the iterations\n",
        "\n",
        "    def distance_map(self):\n",
        "        \"\"\" Returns the average distance map of the weights.\n",
        "            (Each mean is normalized in order to sum up to 1) \"\"\"\n",
        "        um = zeros((self.weights.shape[0],self.weights.shape[1]))\n",
        "        it = nditer(um, flags=['multi_index'])\n",
        "        while not it.finished:\n",
        "            for ii in range(it.multi_index[0]-1,it.multi_index[0]+2):\n",
        "                for jj in range(it.multi_index[1]-1,it.multi_index[1]+2):\n",
        "                    if ii >= 0 and ii < self.weights.shape[0] and jj >= 0 and jj < self.weights.shape[1]:\n",
        "                        um[it.multi_index] += fast_norm(self.weights[ii,jj,:]-self.weights[it.multi_index])\n",
        "            it.iternext()\n",
        "        um = um/um.max()\n",
        "        return um\n",
        "\n",
        "    def activation_response(self,data):\n",
        "        \"\"\" \n",
        "            Returns a matrix where the element i,j is the number of times\n",
        "            that the neuron i,j have been winner.\n",
        "        \"\"\"\n",
        "        a = zeros((self.weights.shape[0],self.weights.shape[1]))\n",
        "        for x in data:\n",
        "            a[self.winner(x)] += 1\n",
        "        return a\n",
        "\n",
        "    def quantization_error(self,data):\n",
        "        \"\"\" \n",
        "            Returns the quantization error computed as the average distance between\n",
        "            each input sample and its best matching unit.            \n",
        "        \"\"\"\n",
        "        error = 0\n",
        "        for x in data:\n",
        "            error += fast_norm(x-self.weights[self.winner(x)])\n",
        "        return error/len(data)\n",
        "\n",
        "    def win_map(self,data):\n",
        "        \"\"\"\n",
        "            Returns a dictionary wm where wm[(i,j)] is a list with all the patterns\n",
        "            that have been mapped in the position i,j.\n",
        "        \"\"\"\n",
        "        winmap = defaultdict(list)\n",
        "        for x in data:\n",
        "            winmap[self.winner(x)].append(x)\n",
        "        return winmap\n",
        "\n",
        "### unit tests\n",
        "from numpy.testing import assert_almost_equal, assert_array_almost_equal, assert_array_equal\n",
        "\n",
        "class TestSom:\n",
        "    def setup_method(self, method):\n",
        "        self.som = Som(5,5,1)\n",
        "        for w in self.som.weights: # checking weights normalization\n",
        "            assert_almost_equal(1.0,linalg.norm(w))\n",
        "        self.som.weights = zeros((5,5)) # fake weights\n",
        "        self.som.weights[2,3] = 5.0\n",
        "        self.som.weights[1,1] = 2.0\n",
        "\n",
        "    def test_fast_norm(self):\n",
        "        assert fast_norm(array([1,3])) == sqrt(1+9)\n",
        "\n",
        "    def test_gaussian(self):\n",
        "        bell = self.som.gaussian((2,2),1)\n",
        "        assert bell.max() == 1.0\n",
        "        assert bell.argmax() == 12  # unravel(12) = (2,2)\n",
        "\n",
        "    def test_win_map(self):\n",
        "        winners = self.som.win_map([5.0,2.0])\n",
        "        assert winners[(2,3)][0] == 5.0\n",
        "        assert winners[(1,1)][0] == 2.0\n",
        "\n",
        "    def test_activation_reponse(self):\n",
        "        response = self.som.activation_response([5.0,2.0])\n",
        "        assert response[2,3] == 1\n",
        "        assert response[1,1] == 1\n",
        "\n",
        "    def test_activate(self):\n",
        "        assert self.som.activate(5.0).argmin() == 13.0  # unravel(13) = (2,3)\n",
        "     \n",
        "    def test_quantization_error(self):\n",
        "        self.som.quantization_error([5,2]) == 0.0\n",
        "        self.som.quantization_error([4,1]) == 0.5\n",
        "\n",
        "    def test_quantization(self):\n",
        "        q = self.som.quantization(array([4,2]))\n",
        "        assert q[0] == 5.0\n",
        "        assert q[1] == 2.0\n",
        "\n",
        "    def test_random_seed(self):\n",
        "        som1 = Som(5,5,2,sigma=1.0,learning_rate=0.5,random_seed=1)\n",
        "        som2 = Som(5,5,2,sigma=1.0,learning_rate=0.5,random_seed=1)\n",
        "        assert_array_almost_equal(som1.weights,som2.weights) # same initialization\n",
        "        data = random.rand(100,2)\n",
        "        som1 = Som(5,5,2,sigma=1.0,learning_rate=0.5,random_seed=1)\n",
        "        som1.train_random(data,10)\n",
        "        som2 = Som(5,5,2,sigma=1.0,learning_rate=0.5,random_seed=1)\n",
        "        som2.train_random(data,10)\n",
        "        assert_array_almost_equal(som1.weights,som2.weights) # same state after training\n",
        "\n",
        "    def test_train_batch(self):\n",
        "        som = Som(5,5,2,sigma=1.0,learning_rate=0.5,random_seed=1)\n",
        "        data = array([[4,2],[3,1]])\n",
        "        q1 = som.quantization_error(data)\n",
        "        som.train_batch(data,10)\n",
        "        assert q1 > som.quantization_error(data)\n",
        "\n",
        "    def test_train_random(self):\n",
        "        som = Som(5,5,2,sigma=1.0,learning_rate=0.5,random_seed=1)\n",
        "        data = array([[4,2],[3,1]])\n",
        "        q1 = som.quantization_error(data)\n",
        "        som.train_random(data,10)\n",
        "        assert q1 > som.quantization_error(data)\n",
        "\n",
        "    def test_random_weights_init(self):\n",
        "        som = Som(2,2,2,random_seed=1)\n",
        "        som.random_weights_init(array([[1.0,.0]]))\n",
        "        for w in som.weights:\n",
        "            assert_array_equal(w[0],array([1.0,.0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as mp\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from pylab import plot, axis, show, pcolor, colorbar, bone"
      ],
      "metadata": {
        "id": "mKtmCbo5vRUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "digits = load_digits()\n",
        "data = digits.data\n",
        "labels = digits.target\n"
      ],
      "metadata": {
        "id": "ctkwwfdsuBZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SOM 모델링\n",
        "som = Som(16,16,64, sigma = 1.0, learning_rate = 0.5)\n",
        "#sigma : 가우시안 네이버후드 함수의 분포 정도\n",
        "#learning rate : SOM의 초기 학습 속도를 스스로 컨트롤할 수 있는 값\n",
        "som.random_weights_init(data)\n",
        "\n",
        "print(\"Initiating SOM\")\n",
        "\n",
        "som.train_random(data, 10000)\n",
        "print(\"SOM Processing Complete\")\n",
        "\n",
        "bone()\n",
        "pcolor(som.distance_map().T)\n",
        "colorbar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "0HxmjjQGuNN5",
        "outputId": "afde00ba-8416-4696-c5b1-69ebddf6edcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initiating SOM\n",
            "SOM Processing Complete\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f5204d53f50>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#합성곱 신경망\n",
        "MNIST 데이터"
      ],
      "metadata": {
        "id": "eH0giv5RLQa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "# 1. MNIST 데이터셋 불러오기\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNZyONq8LU5N",
        "outputId": "07f38c2e-be93-4ce0-927a-ec5b96342767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 데이터 전처리하기\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n"
      ],
      "metadata": {
        "id": "fem9ntXZLuhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 합성곱 신경망 구성하기\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skWd7Y1sNwjV",
        "outputId": "907c5ddb-a75e-4b1f-e86e-281b2f228d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 1, 1, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60,554\n",
            "Trainable params: 60,554\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 모델 컴파일하기\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "dB3UtmcnQXPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 훈련하기\n",
        "model.fit(train_images, train_labels, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "415RCux8FJO9",
        "outputId": "c348bd30-c13a-4145-e8fc-17f0385694f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 57s 30ms/step - loss: 0.2153 - accuracy: 0.9341\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0777 - accuracy: 0.9762\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0541 - accuracy: 0.9835\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0430 - accuracy: 0.9867\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0344 - accuracy: 0.9888\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5199faf9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 모델 평가하기\n",
        "loss, acc = model.evaluate(test_images, test_labels, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcV8zcVqGUEM",
        "outputId": "612dee64-d271-421f-cd56-136552ac5df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 3s - loss: 0.0588 - accuracy: 0.9860 - 3s/epoch - 9ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8aBI94rMGai3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}